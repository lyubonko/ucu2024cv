{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9M6mtQU1LE3"
   },
   "source": [
    "Tutorial 4 (OpenAI vision API)\n",
    "======================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment you will explore the openAI Vision API.\n",
    "\n",
    "**Note**: This tutorial is **optional**. You will need openAI API keys to complete it. Note that if you are using your personal account, completing this tutorial will cost you some money. But not much, one round of experiment (as it is outlined here) will cost less than 1$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "* The <b><font color='red'>red</font></b> color indicates the task that should be done, like <b><font color='red'>[TODO]</font></b>: ...\n",
    "* Addicitional comments, hints are in <b><font color='blue'>blue</font></b>. For example <b><font color='blue'>[HINT]</font></b>: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/vision\n",
    "\n",
    "https://platform.openai.com/docs/guides/fine-tuning/vision\n",
    "\n",
    "https://openai.com/api/pricing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelimiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install fiftyone\n",
    "# !pip install scikit-learn\n",
    "# !pip install tensorboard jupyter-tensorboard\n",
    "# !pip install tqdm\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots a bit nicer\n",
    "plt.matplotlib.rcParams.update({'font.size': 18, 'font.family': 'serif'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_dataset(\n",
    "    dataset: Dataset,\n",
    "    classes_list: list,\n",
    "    used_indexes: list[int] = None,\n",
    "    blacklist_classes: list[int] = None,\n",
    "    n_times: int = None,\n",
    "    max_size: int = None\n",
    ") -> tuple[list[dict], list]:\n",
    "\n",
    "    used_indexes = set(used_indexes or [])\n",
    "    blacklist_classes = set(blacklist_classes or [])\n",
    "    \n",
    "    available_indices = [i for i in range(len(dataset)) if i not in used_indexes]\n",
    "    filtered_dataset = [dataset[i] for i in available_indices]\n",
    "    \n",
    "    max_size = max_size or len(filtered_dataset)\n",
    "    n_times = n_times or (max_size // len(classes_list))\n",
    "    \n",
    "    counter = {label: 0 for label in range(len(classes_list))}\n",
    "    selected_samples = []\n",
    "    selected_indexes = []\n",
    "    samples_count = 0\n",
    "\n",
    "    for i, sample in zip(available_indices, filtered_dataset):\n",
    "        label = sample['label']\n",
    "        if label not in blacklist_classes and counter[label] < n_times and samples_count < max_size:\n",
    "            selected_samples.append(sample)\n",
    "            selected_indexes.append(i)\n",
    "            counter[label] += 1\n",
    "            samples_count += 1\n",
    "\n",
    "    return selected_samples, selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_to_largest_side(image: Image.Image, large_side: int = 512) -> Image.Image:\n",
    "    # Determine the scaling factor based on the larger dimension\n",
    "    scale_factor = large_side / max(image.size)\n",
    "\n",
    "    # Calculate new dimensions using the scaling factor\n",
    "    new_dimensions = tuple(int(dim * scale_factor) for dim in image.size)\n",
    "\n",
    "    # Resize and return the image\n",
    "    return image.resize(new_dimensions, Image.Resampling.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hf_cocoo_dataset(path_coco_o:str , path_data:str, seed:int =42, test_ratio=0.3):\n",
    "    def load_image(example):\n",
    "        example['image'] = Image.open(example['image_path'])\n",
    "        return example\n",
    "\n",
    "    if not os.path.exists(path_coco_o):\n",
    "        url = 'https://drive.google.com/uc?id=1aBfIJN0zo_i80Hv4p7Ch7M8pRzO37qbq'\n",
    "        zip_file_path = os.path.join(path_data, 'ood_coco.zip')\n",
    "        gdown.download(url, zip_file_path, quiet=False)\n",
    "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(path_data)\n",
    "\n",
    "    cocoo_classes_list = os.listdir(path_coco_o)\n",
    "    all_elements_coco = [\n",
    "        (os.path.join(path_coco_o, label, 'val2017', img), index) \n",
    "        for index, label in enumerate(cocoo_classes_list) \n",
    "        for img in os.listdir(os.path.join(path_coco_o, label, 'val2017'))\n",
    "    ]\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    indices = np.arange(len(all_elements_coco))\n",
    "    np.random.shuffle(indices)\n",
    "    n_test = int(len(indices) * test_ratio)\n",
    "\n",
    "    train_indices, test_indices = indices[n_test:], indices[:n_test]\n",
    "    datasets = {}\n",
    "\n",
    "    for split, split_indices in zip(['train', 'test'], [train_indices, test_indices]):\n",
    "        split_data = [(all_elements_coco[i][0], all_elements_coco[i][1]) for i in split_indices]\n",
    "        image_paths, labels = zip(*split_data)\n",
    "        dataset = Dataset.from_dict({'image_path': image_paths, 'label': labels})\n",
    "        datasets[split] = dataset.map(load_image, remove_columns=['image_path'])\n",
    "\n",
    "    return DatasetDict(datasets), cocoo_classes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts and all that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = '''\n",
    "Please analyze the provided image and determine its class.\n",
    "    \n",
    "The eligible classes are as follows:\n",
    "{class_names_list}\n",
    "    \n",
    "Select the class that best represents the image from this list. \n",
    "Do not include any additional information or commentary in your response. \n",
    "Ensure the predicted class is among the eligible classes, and respond with only the class name.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_by_path(image_path: str | Path) -> str:\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def encode_image(pil_image: Image.Image) -> str:\n",
    "    with BytesIO() as buffer:\n",
    "        pil_image.convert('RGB').save(buffer, format='JPEG')\n",
    "        return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "def parse_response(\n",
    "    response: object, \n",
    "    class_labels: list[str]\n",
    ") -> str | None:\n",
    "    \n",
    "    try:\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            pred = data.get('choices', [{}])[0].get('message', {}).get('content')\n",
    "            return pred if pred in class_labels else None\n",
    "    except ValueError as e:\n",
    "        print(f'Error parsing JSON: {e}')\n",
    "        return None\n",
    "\n",
    "def generate_request_with_image(\n",
    "    base64_image: str,\n",
    "    classes_list: list[str],     \n",
    "    true_label: str | None = None,\n",
    "    openai_model_version: str = 'gpt-4o-2024-08-06'\n",
    ") -> dict[str, object]:\n",
    "    \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': base_prompt.format(class_names_list=classes_list)},\n",
    "        {'role': 'user', 'content': [{\n",
    "            'type': 'image_url',\n",
    "            'image_url': {\n",
    "                'url': f'data:image/jpeg;base64,{base64_image}'\n",
    "            }\n",
    "        }]}\n",
    "    ]\n",
    "    \n",
    "    if true_label:\n",
    "        messages.append({'role': 'assistant', 'content': true_label})\n",
    "    \n",
    "    return {\n",
    "        'messages': messages,\n",
    "        'model': openai_model_version\n",
    "    }\n",
    "\n",
    "def generate_requests(\n",
    "    data_set: list[dict[str, object]], \n",
    "    class_labels: list[str],\n",
    "    mode: str = 'test',\n",
    "    model_version: str = 'gpt-4o-2024-08-06'    \n",
    ") -> list[dict[str, object]]:\n",
    "    \n",
    "    def process_sample(sample: dict[str, object]) -> dict[str, object]:\n",
    "        pil_image = (\n",
    "            sample['image'] if 'image' in sample \n",
    "            else Image.open(sample['image_path'])\n",
    "        )\n",
    "        \n",
    "        resized_image = (\n",
    "            resize_image_to_largest_side(pil_image) \n",
    "            if max(pil_image.size) > 512 \n",
    "            else pil_image\n",
    "        )\n",
    "        \n",
    "        true_label = (\n",
    "            class_labels[sample['label']]\n",
    "            if mode == 'train' \n",
    "            else None\n",
    "        )\n",
    "        \n",
    "        return generate_request_with_image(\n",
    "            encode_image(resized_image),\n",
    "            class_labels,\n",
    "            true_label=true_label,\n",
    "            openai_model_version=model_version\n",
    "        )\n",
    "    \n",
    "    return list(map(process_sample, data_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the local folder with the data\n",
    "path_data = './data'\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar10 dataset\n",
    "cifar10_dataset = load_dataset('cifar10', cache_dir=path_data)\n",
    "cifar10_dataset = cifar10_dataset.rename_column(original_column_name='img', new_column_name='image')\n",
    "cifar10_classes_list = cifar10_dataset['train'].features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DTD dataset\n",
    "dtd_dataset = load_dataset('tanganke/dtd', cache_dir=path_data)\n",
    "dtd_classes_list = dtd_dataset['train'].features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO-O dataset\n",
    "path_coco_o = os.path.join(path_data, 'ood_coco')\n",
    "cocoo_dataset, cocoo_classes_list = create_hf_cocoo_dataset(path_coco_o, path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and select 'mini' testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_mini_test, cifar10_mini_test_indexes = create_mini_dataset(cifar10_dataset['test'], cifar10_classes_list, max_size=100)\n",
    "dtd_mini_test, dtd_mini_test_indexes = create_mini_dataset(dtd_dataset['test'], dtd_classes_list, max_size=100)\n",
    "cocoo_mini_test, cocoo_mini_test_indexes = create_mini_dataset(cocoo_dataset['test'], cocoo_classes_list, max_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini_testset, mini_class_labels = cifar10_mini_test, cifar10_classes_list\n",
    "#mini_testset, mini_class_labels = dtd_mini_test, dtd_classes_list\n",
    "mini_testset, mini_class_labels = cocoo_mini_test, cocoo_classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Get openAI key or provide one by hand \n",
    "client = OpenAI()\n",
    "api_key = client.api_key\n",
    "#api_key = ...\n",
    "\n",
    "# Prepare headers\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Authorization': f'Bearer {api_key}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate requests\n",
    "test_requests = generate_requests(mini_testset, mini_class_labels, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ground_truth = []\n",
    "labels_predictations = []\n",
    "for req_json, sample in tqdm(zip(test_requests, mini_testset)):\n",
    "       \n",
    "    # Send request\n",
    "    response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=req_json)\n",
    "\n",
    "    # Parse response\n",
    "    pred = parse_response(response, mini_class_labels)\n",
    "    if pred:\n",
    "        labels_predictations.append(pred)\n",
    "        labels_ground_truth.append(mini_class_labels[sample['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report\n",
    "print(f'* Response success rate: {len(labels_predictations) / len(mini_testset)}\\n')\n",
    "print('* Classification report:\\n')\n",
    "print(classification_report(labels_ground_truth, labels_predictations, target_names=mini_class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation set \n",
    "# We will use the small subset to speed-up and make things not costly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train, mini_train_indexes = create_mini_dataset(cocoo_dataset['train'], cocoo_classes_list, max_size=500)\n",
    "mini_val, _ = create_mini_dataset(cocoo_dataset['train'], cocoo_classes_list, max_size=200, used_indexes=mini_train_indexes)\n",
    "mini_classes_list = cocoo_classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect one sample \n",
    "# indx = 0\n",
    "# print(mini_train[indx]['label'])\n",
    "# print(mini_classes_list[mini_train[indx]['label']])\n",
    "# mini_train[indx]['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of today (Oct 2024) openAI has restrictions on images containing \n",
    "\n",
    "* People\n",
    "* Faces\n",
    "* Children\n",
    "* CAPTCHAs\n",
    "\n",
    "You can read more [here](https://platform.openai.com/docs/guides/fine-tuning/content-moderation-policy).\n",
    "\n",
    "To clean 'people related content' we will use YOLO detector, read here if you would like to learn more this [lib](https://docs.ultralytics.com/) (we will also cover YOLO during our 'object detection' part of the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pred model from YOLO\n",
    "from ultralytics import YOLO\n",
    "model_det = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_person_present(image):\n",
    "    det_results = model_det(image, verbose=False)[0]\n",
    "    detected_classes = [det_results.names[int(cls.item())] for cls in det_results.boxes.cls]\n",
    "    return 'person' in detected_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train = [sample for sample in tqdm(mini_train) if not is_person_present(sample['image'])]\n",
    "mini_val = [sample for sample in tqdm(mini_val) if not is_person_present(sample['image'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats of train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset sizes\n",
    "print('* Sizes:')\n",
    "print('train: ', len(mini_train))\n",
    "print('val:   ', len(mini_val))\n",
    "\n",
    "# Classes \n",
    "print('\\n* Classes:')\n",
    "print('train: ', sorted([mini_classes_list[indx] for indx in set([x['label'] for x in mini_train])]))\n",
    "print('val:   ', sorted([mini_classes_list[indx] for indx in set([x['label'] for x in mini_val])]))\n",
    "\n",
    "# Inspect the distribution of the data\n",
    "print('\\n* Distritubions:')\n",
    "print('train: ', sorted(Counter([mini_classes_list[x['label']] for x in mini_train]).most_common(), key= lambda x :x[0]))\n",
    "print('val:   ', sorted(Counter([mini_classes_list[x['label']] for x in mini_val]).most_common(), key= lambda x :x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate requests to openAI\n",
    "train_requests = generate_requests(mini_train, mini_classes_list, mode='train')\n",
    "val_requests = generate_requests(mini_val, mini_classes_list, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare files\n",
    "fname_train = os.path.join(path_data, 'data_train_openai.jsonl')\n",
    "with open(fname_train, 'w') as file:\n",
    "    for entry in train_requests_selected:\n",
    "        json_line = json.dumps(entry)\n",
    "        file.write(json_line + '\\n')\n",
    "print(f'Data written to {fname_train}')\n",
    "\n",
    "fname_val = os.path.join(path_data, 'data_val_openai.jsonl')\n",
    "with open(fname_val, 'w') as file:\n",
    "    for entry in val_requests_selected:\n",
    "        json_line = json.dumps(entry)\n",
    "        file.write(json_line + '\\n')\n",
    "\n",
    "print(f'Data written to {fname_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to check if the files are there and the sizes are resonable\n",
    "!ls -alh ./data/*.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send files to openAI\n",
    "training_file_upload_response = client.files.create(\n",
    "  file=open(fname_train, 'rb'),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "print(training_file_upload_response)\n",
    "\n",
    "validation_file_upload_response = client.files.create(\n",
    "  file=open(fname_val, 'rb'),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "print(validation_file_upload_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the fine-tuning job\n",
    "# You can monitor the status here: https://platform.openai.com/finetune/\n",
    "\n",
    "fine_tuning_response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_upload_response.id,\n",
    "    validation_file=validation_file_upload_response.id,\n",
    "    suffix='cocoo',\n",
    "    model='gpt-4o-2024-08-06'\n",
    ")\n",
    "fine_tuning_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After a while we can probe how things are going\n",
    "status_response=client.fine_tuning.jobs.retrieve(fine_tuning_response.id)\n",
    "status_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model name from 'status_response' once fine-tuning is finished or from https://platform.openai.com/finetune/ \n",
    "model_name_finetuned = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate requests\n",
    "test_requests = generate_requests(mini_testset, mini_class_labels, mode='test', model_version=model_name_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ground_truth = []\n",
    "labels_predictations = []\n",
    "for req_json, sample in tqdm(zip(test_requests, mini_testset)):\n",
    "       \n",
    "    # Send request\n",
    "    response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=req_json)\n",
    "\n",
    "    # Parse response\n",
    "    pred = parse_response(response, mini_class_labels)\n",
    "    if pred:\n",
    "        labels_predictations.append(pred)\n",
    "        labels_ground_truth.append(mini_class_labels[sample['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report\n",
    "print(f'* Response success rate: {len(labels_predictations) / len(mini_testset)}\\n')\n",
    "print('* Classification report:\\n')\n",
    "print(classification_report(labels_ground_truth, labels_predictations, target_names=mini_class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\">[TODO]</font></b>: Conduct zero-shot experiments for DTD dataset and cifar10 datasets. Compare accuracy to previous experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Q2C1j43ia-PP",
    "j_no4Mw2a-Pc"
   ],
   "name": "ucu_cv2024_module2_practice01.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "cv2024",
   "language": "python",
   "name": "cv2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
